#!/bin/bash

# Script de lancement complet de l'app LLM
# Lance le backend et le frontend simultanÃ©ment

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
BACKEND_DIR="$SCRIPT_DIR/backend"

echo "ğŸš€ LLM AI Chat - Lancement complet"
echo "=================================="

# VÃ©rifier Node.js
if ! command -v node &> /dev/null; then
    echo "âŒ Node.js non trouvÃ©. Installez depuis https://nodejs.org"
    exit 1
fi

# VÃ©rifier Python
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python3 non trouvÃ©. Installez depuis https://www.python.org"
    exit 1
fi

echo "âœ… DÃ©pendances dÃ©tectÃ©es"

# Lancer le backend en arriÃ¨re-plan
echo ""
echo "ğŸ“¦ DÃ©marrage du backend LLM (port 7860)..."
cd "$BACKEND_DIR"

# CrÃ©er venv si nÃ©cessaire
if [ ! -d ".venv" ]; then
    echo "   CrÃ©ation de l'environnement virtuel..."
    python3 -m venv .venv
fi

# Activer venv et installer
source .venv/bin/activate
pip install -q -r requirements.txt

# Lancer le serveur en arriÃ¨re-plan
python main.py &
BACKEND_PID=$!
echo "âœ… Backend lancÃ© (PID: $BACKEND_PID)"

# Retour au dossier principal
cd "$SCRIPT_DIR"

# Attendre que le backend soit prÃªt
echo ""
echo "â³ Attente du serveur Backend..."
sleep 3

# VÃ©rifier que le backend rÃ©pond
if curl -s http://localhost:7860/health > /dev/null 2>&1; then
    echo "âœ… Backend opÃ©rationnel"
else
    echo "âš ï¸  Backend lent Ã  dÃ©marrer, continuant..."
fi

# Lancer le frontend
echo ""
echo "ğŸ¨ DÃ©marrage de l'interface (http://localhost:5173)..."
npm run tauri:dev

# Cleanup
trap "kill $BACKEND_PID" EXIT
